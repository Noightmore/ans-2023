{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d58dc836-625a-4c0a-a840-b23c3ffef10e",
   "metadata": {},
   "source": [
    "# Lineární klasifikace obrázků CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57846d13-17c6-494d-a851-c88e2d363640",
   "metadata": {},
   "source": [
    "Úkolem cvičení je naprogramovat lineární klasifikátor, který bude rozpoznávat objekty z datasetu CIFAR-10.\n",
    "Vstupem je RGB obrázek o rozměrech 32$\\times$32 pixelů a úkolem říci, který z 10 možných objektů (tříd) je na něm zachycen. Možnosti jsou tyto: letadlo, automobil, pták, kočka, jelen, pes, žába, kůň, loď, náklaďák.\n",
    "\n",
    "**Model**\n",
    "- Vstup: $\\boldsymbol{x}$, rozměr $N \\times D$, kde $N$ je počet obrázků a $D$ počet číselných hodnot v jednom obrázku\n",
    "  - Každý řádek je jeden obrázek reprezentovaný jako vektor, čísla v rozmezí 0-1.\n",
    "- Parametr váhy (weights): $\\boldsymbol{w}$, rozměr $D \\times C$\n",
    "- Parametr bias: $\\boldsymbol{b}$, rozměr $C$\n",
    "- Predikované skóre (logity): $\\boldsymbol{s} = \\boldsymbol{x}\\cdot\\boldsymbol{w} + \\boldsymbol{b}$, rozměr $N \\times C$\n",
    "  - Pro každý obrázek predikce $C$ hodnot\n",
    "- Predikovaná třída: $\\boldsymbol{z} = \\arg\\max_c\\boldsymbol{s}$, rozměr $N$\n",
    "  - Pro každý obrázek vybereme třídu s nejvyšším skóre.\n",
    "\n",
    "**Optimalizace**\n",
    "- Kritérium křížová entropie: $l = \\sum_c{p_c \\cdot \\log q_c}$\n",
    "- Metoda Stochastic Gradient Descent (SGD)\n",
    "  - $\\boldsymbol{w} := \\boldsymbol{w} - \\gamma \\frac{dl}{d\\boldsymbol{w}}$\n",
    "  - $\\boldsymbol{b} := \\boldsymbol{b} - \\gamma \\frac{dl}{d\\boldsymbol{w}}$\n",
    "  - Hyperparametr $\\gamma$ značí rychlost učení (learning rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9227fbaf-39c6-4679-bb72-575bc332d642",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3194cbd-6dbc-4fd8-811a-ab65733b8f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')  # import tests\n",
    "from typing import Callable\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import ans\n",
    "from tests import test_linear_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f222a54-2876-4c0f-bb22-be3e9391ac3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(profile='short')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ec2c26-00bc-4e8a-9004-0a0387acb180",
   "metadata": {},
   "source": [
    "# Načtení dat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b11da3-defb-4ec3-b66a-c21d6a019f32",
   "metadata": {},
   "source": [
    "Balík torchvision podporuje některé znamé datasety, mezi něž patří i CIFAR-10. Nemusíme tedy data stahovat z internetu manuálně, torchvision za nás vše obstará automaticky. Data uložíme do adresáře `./data`. Všimněme si flagu `train=True`, který říká, že se má načíst trénovací množina datasetu CIFAR-10 (soubory `data_batch_*`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c464e66e-b25f-4176-b075-795c328bfcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root='../data', train=True, download=True)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df06adc-9a6e-47fe-8448-dcc981218570",
   "metadata": {},
   "source": [
    "Validovat budeme na zbylých 10000 obrázcích. Získáme je nastavením `train=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec5814d-f421-482b-b059-495b06552899",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = torchvision.datasets.CIFAR10(root='../data', train=False, download=True)\n",
    "val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8eb2043-3188-4be7-a6a2-21790c59273d",
   "metadata": {},
   "source": [
    "Seznam tříd je uložen v atributu `.classes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945e1ec4-ba6e-4c5f-a02a-853c54a35fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a13b57e-1d86-4f69-9b25-b7b3d90c207d",
   "metadata": {},
   "source": [
    "Objekt třídy `torchvision.datasets.cifar.CIFAR10` se chová podobně jako pythonovský `list` s tím, že každý jeho prvek je dvojice (obrázek, třída)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682f811d-18ec-4668-b3a1-45548c363f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2810dd-fde7-4fa2-80de-85ccfbc2b0e7",
   "metadata": {},
   "source": [
    "Jak vidíme, 6. prvek datasetu je *dvojice* (`tuple`) sestávající z obrázku a jeho indexu třídy (label, target).\n",
    "\n",
    "- Obrázek je defaultně navrácen jako typ `Image` knihovny Pillow (Python Imaging Library, PIL).\n",
    "\n",
    "- Target je číslo typu `int` označující jednu ze tříd v atributu `.classes`.\n",
    "\n",
    "Všechny obrázky CIFAR-10 datasetu jsou uloženy v atributu `.data`, což je 4D `numpy.ndarray` typu `np.uint8`. První dimenze odpovídá jednotlivým obrázkům, další pak řádkům, sloupcům a kanálům (RGB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff9d30c-fb14-4c6d-88e4-f09b9f609f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_dataset.data), train_dataset.data.shape, train_dataset.data.dtype, train_dataset.data.min(), train_dataset.data.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8eed48-d5bb-4d3b-b3e0-6789c995de0f",
   "metadata": {},
   "source": [
    "Podobně všechny targety jsou uložny v `.targets`, což je `list` o délce počtu obrázků, přičemž každý target číslo typu `int` v rozmezí 0-9, kde 0 značí letadlo (airplane), 1 značí automobil (automobile) atd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4e13aa-0227-46ea-be18-e65e0e18e0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_dataset.targets), len(train_dataset.targets), type(train_dataset.targets[0]), min(train_dataset.targets), max(train_dataset.targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113da300-9165-4031-b589-abce0534934b",
   "metadata": {},
   "source": [
    "Pro lepší představu si vykreslíme sloupec 10 obrázků pro každou z 10 tříd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e7e46f-e14d-4155-92de-de34011be9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "for i, cls in enumerate(train_dataset.classes):\n",
    "    # chceme pouze obrazky aktualni tridy a z nich nahodne vybereme 10\n",
    "    cls_ids = [j for j, y in enumerate(train_dataset.targets) if y == i]\n",
    "    draw_ids = np.random.choice(cls_ids, size=10)\n",
    "    \n",
    "    # pyplot podobne jako MATLAB nabizi funkci subplot pro vykresleni vice grafu do jednoho okna\n",
    "    for j, k in enumerate(draw_ids):\n",
    "        # vykresli 10x10 obrazku, poradi je po radcich, ovsem my budeme vykreslovat po sloupcich,\n",
    "        # tj. kazdy sloupec bude obsahovat 10 prikladu jedne ze trid\n",
    "        plt.subplot(10, 10, j * 10 + i + 1)\n",
    "        \n",
    "        # vyresli obrazek\n",
    "        plt.imshow(train_dataset.data[k])\n",
    "        \n",
    "        # nevykresluj popisky os\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # v prvnim radku pridame nazev grafu (obrazku)\n",
    "        if j == 0:\n",
    "            plt.title(cls, fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b313d57-3df8-4fb7-8d60-5c4fe7d5a56e",
   "metadata": {},
   "source": [
    "# Načítání dat po dávkách"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a27eb00-ebea-4010-a2cc-5eb2ee7d9536",
   "metadata": {},
   "source": [
    "Prvním úkolem bude implementovat načítání dat po dávkách, na kterých se bude klasifikátor učit. Funkcionalita je implementovaná třídou `ans.data.BatchLoader` a nachází se v souboru `ans/data.py`. Třída implementuje metodu `__iter__` a je tedy možné ji použít jako zdroj např. pro `for` cyklus následujícím způsobem:\n",
    "``` python\n",
    "train_loader = ans.data.BatchLoader(\n",
    "    torch.tensor(train_dataset.data),  # input images, shape (50000, 32, 32, 3)\n",
    "    torch.tensor(train_dataset.targets),  # targets, shape (50000,)\n",
    "    batch_size=100,\n",
    "    shuffle=True  # return the data in random order\n",
    ")\n",
    "for inputs, targets in train_loader:\n",
    "    # inputs ... shape (100, 32, 32, 3)\n",
    "    # targets ... shape (100,)\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed880d48-9042-4383-97a0-e88f911990e3",
   "metadata": {},
   "source": [
    "### TODO: implementujte metodu `__iter__` třídy `ans.data.BatchLoader`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72499837-36b6-4b15-baa5-db3d8131e1f7",
   "metadata": {},
   "source": [
    "Implementaci lze zkontrolovat připravenými unit testy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661712f3-3199-4c93-8ad9-616562e69c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_linear_classification.TestBatchLoader.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b900a6c3-908b-4b35-90e8-4e6b54df63d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = ans.data.BatchLoader(\n",
    "    torch.tensor(train_dataset.data),\n",
    "    torch.tensor(train_dataset.targets),\n",
    "    batch_size=5,\n",
    "    shuffle=True\n",
    ")\n",
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e8985c-fce9-4b65-b2fd-d2ff7dafa506",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, targets = next(iter(train_loader))\n",
    "print(type(inputs), inputs.shape, inputs.dtype, inputs.min(), inputs.max())\n",
    "print(type(targets), targets.shape, targets.dtype, targets.min(), targets.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de2457f-76eb-46c1-b244-db40cc83e614",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = ans.data.BatchLoader(\n",
    "    torch.tensor(val_dataset.data),\n",
    "    torch.tensor(val_dataset.targets),\n",
    "    batch_size=5,\n",
    "    shuffle=False\n",
    ")\n",
    "val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7271b447-eb0e-4b64-89a6-429ef762e489",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f1f705-babb-417d-95c9-b1450f389d6c",
   "metadata": {},
   "source": [
    "Data jsou celočiselného typu `torch.uint8`, což jsou čísla v rozmezí 0-255. Pro lepší numerické vlastnosti data převedeme do rozsahu 0-1 a datového typu `torch.float32`, který je pro PyTorch výchozí. Operaci provedeme jednoduchým vydělením max. hodnotou 255. Zároveň obrázky přetvarujeme do vektoru, takže výstup bude mít rozměr (batch_size, počet_pixelů). Celé předzpracování bude implementovat funkce `preprocess`, kterou budeme volat pro každou dávku po jejím načtení z `BatchLoader`u. Normalizovat budeme pouze obrázky, s targety nic dělat nebudeme."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb04038e-77bb-4486-9086-f78442f4db42",
   "metadata": {},
   "source": [
    "### TODO: implementuje funkci `preprocess`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d1507c-2586-4955-92ed-3e4c1e88609c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(inputs: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        inputs: n-dimensional tensor with first dimension of size num_inputs\n",
    "    Returns:\n",
    "        outputs: 2-dimensional tensor; shape (num_inputs, num_features), dtype float32\n",
    "    \"\"\"\n",
    "    \n",
    "    ########################################\n",
    "    # TODO: implement\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ENDTODO\n",
    "    ########################################\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2db5c4-8a24-48e0-841d-49238e224021",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_linear_classification.TestPreprocess.eval(preprocess_fn=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fbe173-2a8f-4e46-a364-00bce057b14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_prep = preprocess(inputs)\n",
    "inputs_prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336171da-83e0-4ba9-b951-d9c260ca4896",
   "metadata": {},
   "source": [
    "# Inicializace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80ae0d8-2221-4280-9744-4f029b30f66e",
   "metadata": {},
   "source": [
    "Váhovou matici $\\boldsymbol{W}$ klasifikátoru inicializujeme na náhodné hodnoty s normálním rozdělením a malou standardní odchylkou. Bias $\\boldsymbol{b}$ inicializujeme vektor nul s odpovídajícím rozměrem. Inicializaci bude provádět funkce `init_params`, která převezme rozměry a požadovanou odchylku (parametr `multiplier`) a vrátí dvojici (weight, bias).\n",
    "\n",
    "Pozn.: nezapomínejme, že obrázky jsou uloženy *po řádcích* a náš model má podobu $\\boldsymbol{s} = \\boldsymbol{x}\\cdot\\boldsymbol{w} + \\boldsymbol{b}$. Od toho se odvíjejí rozměry $\\boldsymbol{w}$ a $\\boldsymbol{b}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcc47a5-47ac-4bc2-95be-f26512e71cd0",
   "metadata": {},
   "source": [
    "### TODO: implementuje funkci `init_params`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676b9d3e-137f-410b-bcbd-3a701fbf8bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(input_dim: int, output_dim: int, multiplier: float = 1e-2) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        input_dim: size of one input\n",
    "        output_dim: size of one output\n",
    "        multiplier: standard deviation of weight\n",
    "    Returns:\n",
    "        weight, bias\n",
    "    \"\"\"\n",
    "    \n",
    "    ########################################\n",
    "    # TODO: implement\n",
    "    \n",
    "    \n",
    "\n",
    "    # ENDTODO\n",
    "    ########################################\n",
    "    \n",
    "    return weight, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8779f2b2-9afc-4c22-9473-ba5e8d8f6342",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_linear_classification.TestInit.eval(init_params_fn=init_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cdec4a-ee27-4246-8c6a-4305cfef3244",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight, bias = init_params(inputs_prep.shape[1], len(train_dataset.classes))\n",
    "weight, bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a2873e-6b7e-4ed3-b0d1-3ec0778a459a",
   "metadata": {},
   "source": [
    "# Výpočet lineárních skóre (logitů)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af0c796-c7bf-41e1-912c-a2cc69c4a820",
   "metadata": {},
   "source": [
    "Nyní vypočteme lineární skóre (logity) jako\n",
    "$$\\boldsymbol{s}_n = \\boldsymbol{x}_n \\cdot \\boldsymbol{w} + \\boldsymbol{b}$$\n",
    "kde\n",
    "- $\\boldsymbol{s}_n = [s_{n,1},\\ldots,s_{n,C}]$ je (řádkový) vektor skóre pro $n$-tý vzorek (obrázek) $\\boldsymbol{x}_n$ a každou z $C$ (= `num_classes`) tříd\n",
    "- $\\boldsymbol{x}_n = [x_{n,1},\\ldots,x_{n,D}]$ je $n$-tý vzorek (obrázek) v dávce reprezentovaný jako (řádkový) vektor s rozměrem $D$ (= `num_features`)\n",
    "- $\\boldsymbol{w} = [w_{d,c}]$ je matice vah klasifikátoru s rozměry $D \\times C$\n",
    "- $\\boldsymbol{b} = [b_1,\\ldots,b_C]$ je bias klasifikátoru - (řádkový) vektor s rozměrem $C$\n",
    "\n",
    "Výpočet bude zajišťovat funkce `calc_linear_scores`, jejímiž vstupy budou\n",
    "- dávka vektorů $\\boldsymbol{x}=[\\boldsymbol{x}_1,\\ldots,\\boldsymbol{x}_N]$ (každý řádek je jeden vektor) s rozměry $N \\times D$\n",
    "- váhová matice $\\boldsymbol{w}$\n",
    "- bias vektor $\\boldsymbol{b}$\n",
    "\n",
    "a výstupem bude\n",
    "- *matice* skóre $\\boldsymbol{S} = [\\boldsymbol{s}_1,\\ldots,\\boldsymbol{s}_N]$ (každý řádek je jeden vektor skóre $\\boldsymbol{s}_n$) s rozměry $N \\times C$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da29391a-11e7-4e73-8718-88f768347453",
   "metadata": {},
   "source": [
    "### TODO: implementuje funkci `calc_linear_scores`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897fffb1-0adb-452b-b45d-ca22a43247bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_linear_scores(inputs: torch.Tensor, weight: torch.Tensor, bias: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        inputs: shape (num_samples, num_features)\n",
    "        weight: shape (num_features, num_classes)\n",
    "        bias: shape (num_classes,)\n",
    "    Returns:\n",
    "        scores: shape (num_samples, num_classes)\n",
    "    \"\"\"\n",
    "    ########################################\n",
    "    # TODO: implement\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ENDTODO\n",
    "    ########################################\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c50d73-7e1c-4335-a255-29efa998761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_linear_classification.TestCalcLinearScores.eval(calc_linear_scores_fn=calc_linear_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2ea5c1-c445-43f5-8b24-aaf8938dccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = calc_linear_scores(inputs_prep, weight, bias)\n",
    "logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f28748-2d2c-4d69-965d-0d4d69759aa3",
   "metadata": {},
   "source": [
    "# Kritérium: softmax cross entropy loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cf3c1f-8487-46bf-ab41-1e1e5faf5a5a",
   "metadata": {},
   "source": [
    "Výstupní pravděpodobnost $c$-té třídy $q_{nc}$ predikovaná klasifikátorem pro $\\boldsymbol{x}_n$ bychom mohli získat aplikací funkce softmax na skóre $\\boldsymbol{s}_n$\n",
    "$$\n",
    "q_{n,c} = \\frac{\\exp{s_{n,c}}}{\\sum_{i=1}^{C}{\\exp{s_{n,i}}}}, c=1,\\ldots,C\n",
    "$$\n",
    "kde\n",
    "- $s_{n,j}$ je predikované skóre jako reálné číslo $(-\\infty, +\\infty)$ $n$-tého vzorku dávky třídy $j$\n",
    "\n",
    "Klasifikátor budeme trénovat optimalizací křížové entropie mezi predikovanými $q_{n,c}$ a skutečnými pravděpodobnostmi $p_{n,c}$\n",
    "$$\n",
    "l_n = -\\sum_c{p_{n,c} \\log q_{n,c}}\n",
    "$$\n",
    "kde\n",
    "- $l_n$ je hodnota kritéria (kladné reálné číslo) pro $n$-tý vzorek $\\boldsymbol{x}_n$ dávky\n",
    "\n",
    "Jelikož pro každý obrázek známe, který objekt je na něm zachycen, skutečné diskrétní rozdělení pravděpodobnosti $\\boldsymbol{p}_n=[p_{n,1},\\ldots,p_{n,C}]$ má pouze jednu hodnotu $p_{n,c}=1$ a to správnou třídu $c=y_n$; ostatní $p_{n,c}=0, c \\ne y_n$ jsou nulové. Jde tedy o tzv. one hot vektor. Sloučením softmaxu a odstraněním nulových členů ve vztahu pro výpočet entropie získáme\n",
    "$$\n",
    "l_n = -\\log q_{n,y_n} = -\\log\\frac{\\exp{s_{n,y_n}}}{\\sum_{c=1}^{C}{\\exp{s_{n,c}}}} = -s_{n,y_n} + \\log\\sum_c\\exp s_{n,c}\n",
    "$$\n",
    "Loss tedy můžeme počítat přímo z lineárních skóre (logitů), což s sebou zároveň přináší výhodu modularity, protože později takto bude možné kritérium jednoduše vyměnit např. za hinge loss a namísto logistické regrese tak trénovat klasifikátor SVM. Kritérium bude počítat funkce `softmax_cross_entropy`, jejímiž vstupy budou\n",
    "- matice skóre $\\boldsymbol{S} = [\\boldsymbol{s}_1,\\ldots,\\boldsymbol{s}_N]$ (každý řádek je jeden vektor skóre $\\boldsymbol{s}_n$) s rozměry $N \\times C$\n",
    "- vektor správných indexů tříd $\\boldsymbol{y} = [y_1, \\ldots, y_N]$ s rozměrem $N$\n",
    "\n",
    "a výstupy budou\n",
    "- celkový loss $l = \\frac{1}{N}\\sum_{n=1}^{N}l_n$ spočítaný jako aritmetický průměr lossů $l_n$ pro jednotlivé predikce $\\boldsymbol{s}_1, \\ldots, \\boldsymbol{s}_N$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198f9f2e-6384-4129-bcf8-df794bdb7265",
   "metadata": {},
   "source": [
    "### TODO: implementujte funkci `softmax_cross_entropy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5123954-28bd-42ec-a7d9-fe69b25be2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_cross_entropy(scores: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        scores: output linear scores (logits before softmax); shape (num_samples, num_classes)\n",
    "        targets: vector of class indicies (integers); shape (num_samples,)\n",
    "    Returns:\n",
    "        loss: averare cross entropy on the batch; tensor containing single number (scalar), e.g. \"tensor(2.23)\"\n",
    "    \"\"\"\n",
    "    \n",
    "    ########################################\n",
    "    # TODO: implement\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ENDTODO\n",
    "    ########################################\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85889837-2623-4a64-aedf-3a3ee2a53267",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_linear_classification.TestSoftmaxCrossEntropy.eval(softmax_cross_entropy_fn=softmax_cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd00a48f-6381-4069-92b5-92ea1521db43",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = softmax_cross_entropy(logits, targets)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfbd2a0-d028-40df-a11c-3d81718df079",
   "metadata": {},
   "source": [
    "# Úspěšnost: accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0802201b-737f-4b80-8413-842c863364f9",
   "metadata": {},
   "source": [
    "Kromě lossu budeme pro lepší orientaci měřit i přesnost (accuracy), byť tuto veličinu nebudeme přímo optimalizovat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c01aff9-fdab-4a21-bac8-3278fbed47d2",
   "metadata": {},
   "source": [
    "### TODO: implementujte funkci `accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd14507d-43a6-4be6-89f5-c473620dcdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(scores: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        scores: output linear scores (logits before softmax); shape (num_samples, num_classes)\n",
    "        targets: vector of class indicies (integers); shape (num_samples,)\n",
    "    Returns:\n",
    "        acc: averare accuracy on the batch; tensor containing single number (scalar), e.g. \"tensor(0.364)\"\n",
    "    \"\"\"\n",
    "    \n",
    "    ########################################\n",
    "    # TODO: implement\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ENDTODO\n",
    "    ########################################\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86ce42d-db54-43fb-bc40-aa776d5b5137",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_linear_classification.TestAccuracy.eval(accuracy_fn=accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddc1bed-4a6f-41cf-99bc-96f6af90defd",
   "metadata": {},
   "source": [
    "# Gradient na parametry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43a72dc-0193-4153-9fde-9f2e534c9226",
   "metadata": {},
   "source": [
    "Optimalizace lossu $l$ bude probíhat stochastickou metodou nejvějtšího spádu (Stochastic Gradient Descent, SGD). K tomu potřebujeme znát gradient na jednotlivé parametry, na kterých $l$ závisí:\n",
    "\n",
    "Gradient na $c$-tý *sloupec* $\\boldsymbol{w}_{:,c}$ matice $\\boldsymbol{w}$ platný pro jeden vstup $\\boldsymbol{x}_n$:\n",
    "$$\n",
    "\\frac{\\partial l_n}{\\partial \\boldsymbol{w}_{:,c}} = (q_{n,c} - p_{n,c})\\cdot\\boldsymbol{x}_n\n",
    "$$\n",
    "kde\n",
    "- $\\partial l_n/\\partial \\boldsymbol{w}_{:,c}$ má rozměr $D \\times C$, tj. shodný s $\\boldsymbol{w}$\n",
    "- $\\boldsymbol{x}_n = [x_{n,1}, \\ldots, x_{n,D}]$ je $n$-tý vzorek dávky jako řádkový vektor s rozměrem $D$\n",
    "- $q_{n,c}$ je pravděpodobnost (reálné číslo) $c$-té třídy predikovaná pro $x_n$\n",
    "- $p_{n,c}$ je cílová požadovaná pravděpodobnost (reálné číslo) pro $x_n$\n",
    "\n",
    "Gradient na $c$-tý prvek biasu platný pro jeden vstup $\\boldsymbol{x}_n$:\n",
    "$$\\frac{\\partial l_n}{\\partial b_c} = (q_{n,c} - p_{n,c})$$\n",
    "\n",
    "Celkový gradient $\\textrm{d}l/\\textrm{d}\\boldsymbol{w}_{:,c}$ na $c$-tý sloupec vah za celou dávku získáme jako **průměr dílčích příspěvků** za jednotlivé vstupy\n",
    "$$\n",
    "\\frac{\\textrm{d}l}{\\textrm{d}\\boldsymbol{w}_{:,c}} = \\frac{1}{N}\\sum_{n=1}^N{ \\frac{\\partial{l}_n}{\\partial \\boldsymbol{w}_{:,c}} }\n",
    "$$\n",
    "- $N$ je počet vzorků $x_n$ v dávce\n",
    "\n",
    "Analogicky platí shodně i pro bias.\n",
    "\n",
    "Oba celkové gradienty za dávku bude vracet funkce `softmax_cross_entropy_gradients`, přičemž vstupem jí budou potřebné proměnné, tj.\n",
    "- dávka vstupů $\\boldsymbol{x} = [\\boldsymbol{x}_1, \\ldots, \\boldsymbol{x}_N]$ s rozměrem $N \\times D$\n",
    "- matice skóre $\\boldsymbol{s} = [\\boldsymbol{s}_1, \\ldots, \\boldsymbol{s}_N]$ s rozměrem $N \\times C$ \n",
    "- vektor správných indexů třídy (targetů) $\\boldsymbol{y} = [y_1, \\ldots, y_N]$ s rozměrem $N$, $y_c \\in \\{1, \\ldots, C\\}$\n",
    "\n",
    "a výstupem budou\n",
    "- gradient na váhovou matici $\\overline{\\boldsymbol{w}} = \\textrm{d}l/\\textrm{d}\\boldsymbol{w}$ jako matice s rozměrem $D \\times C$\n",
    "- gradient na bias $\\overline{\\boldsymbol{b}} = \\textrm{d}l/\\textrm{d}\\boldsymbol{b}$ jako vektor s rozměrem $C$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25a5345-491f-4620-a586-d85a09948bb8",
   "metadata": {},
   "source": [
    "### TODO: implementuje funkci `softmax_cross_entropy_gradients`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb9902f-cef4-4ce0-aacf-8cfe226b4550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_cross_entropy_gradients(\n",
    "    inputs: torch.Tensor,\n",
    "    logits: torch.Tensor,\n",
    "    targets: torch.Tensor\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    ########################################\n",
    "    # TODO: implement\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ENDTODO\n",
    "    ########################################\n",
    "    \n",
    "    return dweight, dbias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d723c3-4e87-4b49-841a-b4f88d609763",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_linear_classification.TestSoftmaxCrossEntropyGradients.eval(softmax_cross_entropy_gradients_fn=softmax_cross_entropy_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad41262-2023-4601-aa5f-e850e3b5b09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dweight, dbias = softmax_cross_entropy_gradients(inputs_prep, logits, targets)\n",
    "dweight, dbias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fa5039-cb42-4a84-b7ef-1ce96354cde1",
   "metadata": {},
   "source": [
    "# Update parametrů\n",
    "\n",
    "Update bude probíhat metodou největšího spádu (Gradient Descent), tj. od aktuáního odhadu parametrů $\\boldsymbol{\\theta}$ odečteme gradient $\\textrm{d}l/\\textrm{d}\\boldsymbol{\\theta}$ přeškálovaný krokem $\\gamma$:\n",
    "\n",
    "$$\\boldsymbol{\\theta} := \\boldsymbol{\\theta} - \\gamma \\frac{\\textrm{d}l}{\\textrm{d}\\boldsymbol{\\theta}}$$\n",
    "\n",
    "Update implementujeme jako funkci, která převezme parametr, gradient na něj a krok učení $\\gamma$ a parametr updatuje. Nebude přitom bytečně vytvářet jeho kopii, vše proběhne modifikací původního tensoru, anglicky tzv. inplace."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2bc923-f4bb-460f-988c-17edeb0bc523",
   "metadata": {},
   "source": [
    "### TODO: implementuje funkci `update_param_inplace`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52661bec-869f-491f-a379-0029dc415d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_param_inplace(param: torch.Tensor, dparam: torch.Tensor, learning_rate: float) -> None:\n",
    "    ########################################\n",
    "    # TODO: implement\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ENDTODO\n",
    "    ########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f94f77b-1e63-4971-801b-aee680c8686d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_linear_classification.TestUpdateParamInplace.eval(update_param_inplace_fn=update_param_inplace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8996b7f-7704-4c02-8fab-e66fd153d421",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06e87d0-534c-4594-b6ef-97ff9a02fd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_param_inplace(weight, dweight, 0.1)\n",
    "update_param_inplace(bias, dbias, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f9e8df-c880-4be6-aba3-020acb374ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight, bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539151d0-9250-43dd-b9f5-18103bbf05cf",
   "metadata": {},
   "source": [
    "# Spojení všech kroků dohromady: funkce `train_step` a `val_step`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32818ecb-3c97-44d9-b026-8ce533190e53",
   "metadata": {},
   "source": [
    "Nyní spojíme všechny kroky do jedné funkce `train_step_softmax`, která převezme dávku vzorků, aktuální parametry klasifikátoru a hyperparametr krok učení a provede jeden krok směrem k mnimializaci křížové entropie na dávce. Funkce vrátí hodnotu lossu a přesnosti (accuracy) dosaženou na dávce."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33de0648-e600-4f1e-ae5f-05da3d099efa",
   "metadata": {},
   "source": [
    "### TODO: implementuje funkci `train_step_softmax`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fab2ee-e970-4f1d-bd33-d042099378fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step_softmax(\n",
    "    inputs: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    weight: torch.Tensor,\n",
    "    bias: torch.Tensor,\n",
    "    learning_rate: float = 1e-3\n",
    ") -> tuple[float, float]:\n",
    "    ########################################\n",
    "    # TODO: implement\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ENDTODO\n",
    "    ########################################\n",
    "    \n",
    "    return loss.item(), acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c21bf56-d65a-4a0d-8c69-9b49c7ee7c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_linear_classification.TestTrainStepSoftmax.eval(train_step_softmax_fn=train_step_softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706f07f7-4099-4676-9849-d13dacc01ab7",
   "metadata": {},
   "source": [
    "### TODO: implementuje funkci `val_step`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b7d3e4-6a03-4756-8a79-0c07e12b89e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def val_step(\n",
    "    inputs: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    weight: torch.Tensor,\n",
    "    bias: torch.Tensor,\n",
    "    loss_fn: Callable[[torch.Tensor, torch.Tensor], tuple[float, float]]  # e.g. softmax_cross_entropy\n",
    ") -> tuple[float, float]:\n",
    "    ########################################\n",
    "    # TODO: implement\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ENDTODO\n",
    "    ########################################\n",
    "    \n",
    "    return loss.item(), acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a987660-4b95-4cae-8d1e-869157e4ad11",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_linear_classification.TestValStep.eval(val_step_fn=val_step, loss_fn=softmax_cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e703e9c8-0f27-468d-8bca-eea789eab230",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate(\n",
    "    loader: ans.data.BatchLoader,\n",
    "    weight: torch.Tensor,\n",
    "    bias: torch.Tensor,\n",
    "    loss_fn: Callable[[torch.Tensor, torch.Tensor], tuple[float, float]]  # e.g. softmax_cross_entropy\n",
    ") -> tuple[float, float]:\n",
    "    total_loss = 0.\n",
    "    total_acc = 0.\n",
    "    for inputs, targets in loader:\n",
    "        loss, acc = val_step(inputs, targets, weight, bias, loss_fn)\n",
    "        total_loss += loss\n",
    "        total_acc += acc\n",
    "    return total_loss / len(loader), total_acc / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566e4833-7041-4975-ab83-b03798609d62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ans.utils.seed_everything(0)\n",
    "\n",
    "# hyperparameters\n",
    "num_epochs = 50\n",
    "learning_rate = 5e-3\n",
    "\n",
    "# data loaders\n",
    "train_loader = ans.data.BatchLoader(\n",
    "    torch.tensor(train_dataset.data),\n",
    "    torch.tensor(train_dataset.targets),\n",
    "    batch_size=100,\n",
    "    shuffle=True\n",
    ")\n",
    "val_loader = ans.data.BatchLoader(\n",
    "    torch.tensor(val_dataset.data),\n",
    "    torch.tensor(val_dataset.targets),\n",
    "    batch_size=100,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# init parameters\n",
    "weight, bias = init_params(np.prod(train_dataset.data.shape[1:]), len(train_dataset.classes), multiplier=1e-3)\n",
    "\n",
    "# validate once before training\n",
    "train_loss, train_acc = validate(train_loader, weight, bias, softmax_cross_entropy)\n",
    "val_loss, val_acc = validate(val_loader, weight, bias, softmax_cross_entropy)\n",
    "print(f\"after init: train_loss={train_loss:.5f}, train_acc={train_acc:.3f}, val_loss={val_loss:.5f}, val_acc={val_acc:.3f}\")\n",
    "\n",
    "# optimize\n",
    "for epoch in range(num_epochs):\n",
    "    # train loop\n",
    "    for inputs, targets in train_loader:\n",
    "        loss, acc = train_step_softmax(inputs, targets, weight, bias, learning_rate=learning_rate)\n",
    "        train_loss = 0.99 * train_loss + 0.01 * loss\n",
    "        train_acc = 0.99 * train_acc + 0.01 * acc\n",
    "    \n",
    "    # validation loop\n",
    "    # train_loss, train_acc = validate(train_loader, weight, bias, softmax_cross_entropy)\n",
    "    val_loss, val_acc = validate(val_loader, weight, bias, softmax_cross_entropy)\n",
    "    \n",
    "    # print\n",
    "    print(f\"epoch {epoch + 1}: train_loss={train_loss:.5f}, train_acc={train_acc:.3f}, val_loss={val_loss:.5f}, val_acc={val_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818ad58e-6aba-4a3d-a8e0-edd209f53a58",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ea2ae1-9bb8-4c96-be8c-6ed4bc47b0ad",
   "metadata": {},
   "source": [
    "SVM je softmaxu velmi podobné. Z pohledu neuronových sítí se liší pouze způsobem výpočtu lossu - místo (softmax) cross entropy použijeme hinge loss:\n",
    "$$l_n = \\sum_{c\\ne y_n}\\max(0, 1 + s_{n,c} - s_{n,y_n})$$\n",
    "kde:\n",
    "- $y_n \\in \\{1, \\ldots, C\\}$ je správný index třídy (celé číslo) na vzorku (obrázku) $\\boldsymbol{x}_n$\n",
    "- $s_{n,i}$ je skóre (logity) predikované lineárním klasifikátorem pro $n$-tý obrázek a $i$-tou třídu.\n",
    "\n",
    "Podobně jako u `softmax_cross_entropy` celkový loss\n",
    "$$\n",
    "l = \\frac{1}{N}\\sum_{n=1}^{N}l_n\n",
    "$$\n",
    "spočítáme jako aritmetický průměr lossů $l_n$ pro jednotlivé predikce $\\boldsymbol{s}_1, \\ldots, \\boldsymbol{s}_N$.\n",
    "\n",
    "Gradient na $c$-tý sloupec $\\boldsymbol{w}_{:,c}$ váhové matice $\\boldsymbol{w}$ pak je\n",
    "$$\n",
    "\\frac{\\partial l_n}{\\partial \\boldsymbol{w}_{:,c}} = \\begin{cases}\n",
    "    \\sum_{c\\ne y_n}\\mathbb{1}(1 + s_{n,c} - s_{n,y_n} > 0)\\cdot\\boldsymbol{x}_n & \\textrm{pokud} & c = y_n \\\\\n",
    "    \\mathbb{1}(1 + s_{n,c} - s_{n,y_n} > 0) \\cdot \\boldsymbol{x}_n & \\textrm{pokud} & c \\ne y_n\n",
    "\\end{cases}\n",
    "$$\n",
    "kde\n",
    "- $\\mathbb{1}(\\cdot) = 1$, pokud podmínka $\\cdot$ je splněna, jinak $\\mathbb{1}(\\cdot) = 0$\n",
    "\n",
    "Jelikož dílčí lossy za jednotliové vzorky v dávce průměrujeme, i jejich gradienty je nutné zprůměrovat\n",
    "$$\n",
    "\\frac{\\textrm{d}l}{\\textrm{d}\\boldsymbol{w}_{:,c}} = \\frac{1}{N} \\sum_{n=1}^{N}{ \\frac{\\partial l_n}{\\partial \\boldsymbol{w}_{:,c}} }\n",
    "$$\n",
    "Pro biasy platí vše podobně jako pro váhy, pouze bez násobení $\\boldsymbol{x}_n$\n",
    "$$\n",
    "\\frac{\\partial l_n}{\\partial b_c} = \\begin{cases}\n",
    "    \\sum_{c\\ne y_n}\\mathbb{1}(1 + s_{n,c} - s_{n,y_n} > 0) & \\textrm{pokud} & c = y_n \\\\\n",
    "    \\mathbb{1}(1 + s_{n,c} - s_{n,y_n} > 0) & \\textrm{pokud} & c \\ne y_n\n",
    "\\end{cases}\n",
    "$$\n",
    "a\n",
    "$$\n",
    "\\frac{\\textrm{d}l}{\\textrm{d}b_c} = \\frac{1}{N} \\sum_{n=1}^{N}{ \\frac{\\partial l_n}{\\partial b_c} }\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbdb641-d918-4a4e-80f4-3fa302cb4580",
   "metadata": {},
   "source": [
    "### TODO: implementuje funkce `hinge_loss`, `hinge_loss_gradients` a `train_step_svm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2e8cb8-3823-4fff-bfc9-092841792a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hinge_loss(scores: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        scores: output from linear classifier, i.e. the pre-softmax logits; shape (num_samples, num_classes)\n",
    "        targets: vector of class indicies (integers); shape (num_samples,)\n",
    "    Returns:\n",
    "        loss: average Weston-Watkins hinge loss on the batch; tensor containing single number (scalar), e.g. \"tensor(2.374)\"\n",
    "    \"\"\"\n",
    "    \n",
    "    ########################################\n",
    "    # TODO: implement\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ENDTODO\n",
    "    ########################################\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e588ea1e-3aeb-4c38-a874-92ee52c29bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_linear_classification.TestHingeLoss.eval(hinge_loss_fn=hinge_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7ee48c-6fc4-456b-a98e-85c74efbd0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hinge_loss_gradients(\n",
    "    inputs: torch.Tensor,\n",
    "    scores: torch.Tensor,\n",
    "    targets: torch.Tensor\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \n",
    "    ########################################\n",
    "    # TODO: implement\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ENDTODO\n",
    "    ########################################\n",
    "    \n",
    "    return dweight, dbias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b35c116-e903-4744-8746-18051bd05dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_linear_classification.TestHingeLossGradients.eval(hinge_loss_gradients_fn=hinge_loss_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06028d3c-43a9-4b85-b528-031630191ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step_svm(\n",
    "    inputs: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    weight: torch.Tensor,\n",
    "    bias: torch.Tensor,\n",
    "    learning_rate: float = 1e-3\n",
    ") -> tuple[float, float]:\n",
    "    ########################################\n",
    "    # TODO: implement\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ENDTODO\n",
    "    ########################################\n",
    "    \n",
    "    return loss.item(), acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f53866-fc54-44a5-bc59-61838a49897c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_linear_classification.TestTrainStepSVM.eval(train_step_svm_fn=train_step_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a84bdda-662e-49da-949f-df2c20f1caf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans.utils.seed_everything(0)\n",
    "\n",
    "# hyperparameters\n",
    "num_epochs = 50\n",
    "learning_rate = 5e-4\n",
    "\n",
    "# data loaders\n",
    "train_loader = ans.data.BatchLoader(\n",
    "    torch.tensor(train_dataset.data),\n",
    "    torch.tensor(train_dataset.targets),\n",
    "    batch_size=100,\n",
    "    shuffle=True\n",
    ")\n",
    "val_loader = ans.data.BatchLoader(\n",
    "    torch.tensor(val_dataset.data),\n",
    "    torch.tensor(val_dataset.targets),\n",
    "    batch_size=100,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# init parameters\n",
    "weight, bias = init_params(np.prod(train_dataset.data.shape[1:]), len(train_dataset.classes), multiplier=1e-3)\n",
    "\n",
    "# validate once before training\n",
    "train_loss, train_acc = validate(train_loader, weight, bias, hinge_loss)\n",
    "val_loss, val_acc = validate(val_loader, weight, bias, hinge_loss)\n",
    "print(f\"after init: train_loss={train_loss:.5f}, train_acc={train_acc:.3f}, val_loss={val_loss:.5f}, val_acc={val_acc:.3f}\")\n",
    "\n",
    "# optimize\n",
    "for epoch in range(num_epochs):\n",
    "    # train loop\n",
    "    for xb, yb in train_loader:\n",
    "        loss, acc = train_step_svm(xb, yb, weight, bias, learning_rate=learning_rate)\n",
    "        train_loss = 0.99 * train_loss + 0.01 * loss\n",
    "        train_acc = 0.99 * train_acc + 0.01 * acc\n",
    "    \n",
    "    # validation loop\n",
    "    # train_loss, train_acc = validate(train_loader, weight, bias, hinge_loss)\n",
    "    val_loss, val_acc = validate(val_loader, weight, bias, hinge_loss)\n",
    "    \n",
    "    # print\n",
    "    print(f\"epoch {epoch + 1}: train_loss={train_loss:.5f}, train_acc={train_acc:.3f}, val_loss={val_loss:.5f}, val_acc={val_acc:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ans22",
   "language": "python",
   "name": "ans22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Oct 13 2022, 21:23:06) [MSC v.1916 64 bit (AMD64)]"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
